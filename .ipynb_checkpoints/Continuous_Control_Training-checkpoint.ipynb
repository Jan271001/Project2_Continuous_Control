{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2deb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from agent import Agent\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f4ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Env_20_Agents/Reacher_Linux/Reacher.x86_64', no_graphics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68a52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278ac442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6076e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition hyperparameters and trainingsconditions\n",
    "n_episodes = 300\n",
    "max_noice= 1.0\n",
    "noice_decay = 0.995\n",
    "training_mode = True\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b34480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 Score:1.1864999734796584 Mean Score(last 100 episodes):1.1864999734796584 Duration episode:04m21s Duration training:00h04m21s\n",
      "Episode:1 Score:2.2639999493956564 Mean Score(last 100 episodes):1.7252499614376575 Duration episode:04m43s Duration training:00h09m05s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent = Agent(state_size, action_size, random_seed, max_noice, noice_decay)\n",
    "\n",
    "#train the agent\n",
    "def ddpg_train(n_episodes):\n",
    "    #list containing scores from each episode\n",
    "    scores = []\n",
    "    #list containing means over last 100 episodes\n",
    "    means = []\n",
    "    #last 100 scores\n",
    "    scores_window = deque(maxlen = 100)\n",
    "    # messure time for achieving a mean score over 30\n",
    "    start_time = time.time()\n",
    "    for episode in range(n_episodes):\n",
    "        # messure time for one episode\n",
    "        start_episode = time.time()\n",
    "        # Reset the enviroment\n",
    "        env_info = env.reset(train_mode=training_mode)[brain_name] \n",
    "        cur_states = env_info.vector_observations\n",
    "        score = np.zeros(num_agents)\n",
    "        # initialize timestep\n",
    "        timestep = 0\n",
    "        # reset noise\n",
    "        agent.reset()\n",
    "        while True:\n",
    "            # Choose best action for given network\n",
    "            actions = agent.act(cur_states, add_noise = True)\n",
    "            # Action is performed and new state, reward, info are received. \n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            # get next state \n",
    "            next_states = env_info.vector_observations\n",
    "            # see if episode is finished\n",
    "            dones = env_info.local_done\n",
    "            # get reward\n",
    "            rewards = env_info.rewards\n",
    "            # save experience to replay buffer, perform learning step at defined interval\"\n",
    "            for cur_state, action, reward, next_state, done in zip(cur_states, \n",
    "                                                                   actions, \n",
    "                                                                   rewards, \n",
    "                                                                   next_states, \n",
    "                                                                   dones):\n",
    "                # current state, action, reward, new state are stored in the experience replay\"\n",
    "                agent.step(cur_state, action, reward, next_state, done, timestep)\n",
    "            # roll over new state\n",
    "            cur_states = next_states      \n",
    "            #add reward to score\n",
    "            score += rewards\n",
    "            # count timestep\n",
    "            timestep+=1\n",
    "            \n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        # calculate time\n",
    "        time_episode = time.time() - start_episode\n",
    "        time_entire = time.time() - start_time\n",
    "        #save most recent score\n",
    "        scores_window.append(score)\n",
    "        scores.append(score)\n",
    "        mean = np.mean(scores_window)\n",
    "        means.append(mean)\n",
    "        print(\"Episode:\" + str(episode) + \" Score:\" + str(np.mean(score)) + \n",
    "              \" Mean Score(last 100 episodes):\" + str(np.mean(scores_window)) +\n",
    "              \" Duration episode:\" + time.strftime('%Mm%Ss', time.gmtime(time_episode)) + \n",
    "              \" Duration training:\" + time.strftime('%Hh%Mm%Ss', time.gmtime(time_entire)))\n",
    "        \n",
    "        # save model weights\n",
    "        if (episode+1) % 10 == 0 or np.mean(scores_window) >= 30:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_Actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_Critic.pth')\n",
    "            if np.mean(scores_window) >= 30:\n",
    "                print(\"Environment solved in \" + str(episode) + \" episodes. Mean score over all 20 agents \" +\n",
    "                      str(np.mean(scores_window)) + \" for the last 100 episodes\")\n",
    "    \n",
    "    return scores, means\n",
    "\n",
    "scores, means = ddpg_train(n_episodes)\n",
    "\n",
    "episode_scores = []\n",
    "for record in scores:\n",
    "    episode_scores.append(np.mean(record))\n",
    "\n",
    "#plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(episode_scores)), episode_scores, label = \"score\")\n",
    "plt.plot(np.arange(len(means)), means, label = \"mean\")\n",
    "plt.axhline(y=30, color='r', linestyle='--', label=\"target\")\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3cf90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
